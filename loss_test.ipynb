{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from src import losses\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from torch.distributions import MultivariateNormal as MVN\n",
    "from torch.utils.data import Dataset\n",
    "import scipy.stats as st\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred   = torch.rand(512, 1, 16, 16)\n",
    "target = torch.rand(512, 1, 16, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize = (14, 5))\n",
    "\n",
    "pred_ravel = torch.flatten(pred)\n",
    "target_raval = torch.flatten(target)\n",
    "sns.histplot(pred_ravel, ax = axs[0])\n",
    "sns.histplot(target_raval, ax = axs[1])\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1648)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = losses.weighted_mse_loss(pred.to(device), target.to(device), weights=None)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12.4842, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmc = losses.BMCLoss(init_noise_sigma = 1.0)\n",
    "loss = bmc(pred.to(device), target.to(device))\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12.4842)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmc = losses.BMCLoss(init_noise_sigma = 1.0)\n",
    "loss = bmc(pred.to(device), target.to(device))\n",
    "loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReweightL2(_Loss):\n",
    "    def __init__(self, train_dist, reweight='inverse'):\n",
    "        super(ReweightL2, self).__init__()\n",
    "        self.reweight = reweight\n",
    "        self.train_dist = train_dist\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        reweight = self.reweight\n",
    "        prob = self.train_dist.log_prob(target).exp().squeeze(-1)\n",
    "        if reweight == 'inverse':\n",
    "            inv_prob = prob.pow(-1)\n",
    "        elif reweight == 'sqrt_inv':\n",
    "            inv_prob = prob.pow(-0.5)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        inv_prob = inv_prob / inv_prob.sum()\n",
    "        loss = F.mse_loss(pred, target, reduction='none').sum(-1) * inv_prob\n",
    "        loss = loss.sum()\n",
    "        return loss\n",
    "\n",
    "\n",
    "class GAILossMD(_Loss):\n",
    "    \"\"\"\n",
    "    Multi-Dimension version GAI, compatible with 1-D GAI\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, init_noise_sigma, gmm):\n",
    "        super(GAILossMD, self).__init__()\n",
    "        self.gmm = gmm\n",
    "        self.gmm = {k: torch.tensor(self.gmm[k]) for k in self.gmm}\n",
    "        self.noise_sigma = torch.nn.Parameter(torch.tensor(init_noise_sigma))\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        noise_var = self.noise_sigma ** 2\n",
    "        loss = gai_loss_md(pred, target, self.gmm, noise_var)\n",
    "        return loss\n",
    "\n",
    "\n",
    "def gai_loss_md(pred, target, gmm, noise_var):\n",
    "    I = torch.eye(pred.shape[-1])\n",
    "    mse_term = -MVN(pred, noise_var*I).log_prob(target)\n",
    "    balancing_term = MVN(gmm['means'], gmm['variances']+noise_var*I).log_prob(pred.unsqueeze(1)) + gmm['weights'].log()\n",
    "    balancing_term = torch.logsumexp(balancing_term, dim=1)\n",
    "    loss = mse_term + balancing_term\n",
    "    loss = loss * (2 * noise_var).detach()\n",
    "    return loss.mean()\n",
    "\n",
    "\n",
    "class BMCLossMD(_Loss):\n",
    "    \"\"\"\n",
    "    Multi-Dimension version BMC, compatible with 1-D BMC\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, init_noise_sigma):\n",
    "        super(BMCLossMD, self).__init__()\n",
    "        self.noise_sigma = torch.nn.Parameter(torch.tensor(init_noise_sigma))\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        noise_var = self.noise_sigma ** 2\n",
    "        loss = bmc_loss_md(pred, target, noise_var)\n",
    "        return loss\n",
    "\n",
    "\n",
    "def bmc_loss_md(pred, target, noise_var):\n",
    "    I = torch.eye(pred.shape[-1])\n",
    "    logits = MVN(pred.unsqueeze(1), noise_var*I).log_prob(target.unsqueeze(0))\n",
    "    loss = F.cross_entropy(logits, torch.arange(pred.shape[0]))\n",
    "    loss = loss * (2 * noise_var).detach()\n",
    "    return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========== CONSTANTS ==============\n",
    "# Training\n",
    "NUM_EPOCHS = 10000\n",
    "PRINT_FREQ = NUM_EPOCHS // 10\n",
    "BATCH_SIZE = 256\n",
    "NUM_TRAIN_ITERS = 4\n",
    "NUM_VAL_ITERS = 1\n",
    "NUM_TRAIN_SAMPLES = BATCH_SIZE * NUM_TRAIN_ITERS\n",
    "NUM_VAL_SAMPLES = BATCH_SIZE * NUM_VAL_ITERS\n",
    "NUM_TEST_SAMPLES = BATCH_SIZE * NUM_VAL_ITERS\n",
    "\n",
    "# Dimensions\n",
    "X_DIM = 2\n",
    "Y_DIM = 2\n",
    "\n",
    "# Data Range\n",
    "Y_UB = torch.ones(Y_DIM) * 5\n",
    "Y_LB = torch.ones(Y_DIM) * -5\n",
    "\n",
    "# Linear Relation and Noise Scale\n",
    "NOISE_SIGMA = 1.\n",
    "NOISE_COVARIANCE = torch.eye(Y_DIM) * (NOISE_SIGMA ** 2)\n",
    "ORACLE_MATRIX = torch.randn([X_DIM, Y_DIM]) * 0.01\n",
    "\n",
    "# Normal Distribution Parameters\n",
    "Y_COVARIANCE = torch.eye(Y_DIM)\n",
    "Y_COVARIANCE = Y_COVARIANCE * 0.5 + torch.ones_like(Y_COVARIANCE) * 0.5\n",
    "Y_MEAN = (Y_LB + Y_UB) / 2\n",
    "# Specify which training distribution to use\n",
    "TRAIN_DIST = 'normal'\n",
    "\n",
    "# predefine distributions\n",
    "DIST_DICT = {\n",
    "    'uniform': torch.distributions.Uniform(Y_LB, Y_UB),\n",
    "    'normal': torch.distributions.MultivariateNormal(loc=Y_MEAN, covariance_matrix=Y_COVARIANCE)\n",
    "}\n",
    "\n",
    "CRITERIA_TO_USE = [\n",
    "    'MSE',\n",
    "    'Reweight',\n",
    "    'GAI',\n",
    "    'BMC',\n",
    "    'GAI Learnable Noise',\n",
    "    'BMC Learnable Noise'\n",
    "]\n",
    "# ======= END OF CONSTANTS =========="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    # This function will never be called, so we leave the inverse here\n",
    "    y = ORACLE_MATRIX.inverse() @ x.unsqueeze(-1)\n",
    "    return y.squeeze()\n",
    "\n",
    "\n",
    "def f_inv(y):\n",
    "    x = ORACLE_MATRIX @ y.unsqueeze(-1)\n",
    "    return x.squeeze()\n",
    "\n",
    "class AverageMeter(object):\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {avg' + self.fmt + '}'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class DummyDataset(Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.inputs[index], self.targets[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "\n",
    "def get_gmm(dist, n_components):\n",
    "    # fit a **ground truth** label distribution\n",
    "    all_labels = dist.sample([10000, ])     # assume sufficient samples\n",
    "    if len(all_labels.shape) == 1:\n",
    "        all_labels = all_labels.unsqueeze(-1)\n",
    "    gmm = GaussianMixture(n_components=n_components).fit(all_labels)\n",
    "    gmm_dict = {'means': gmm.means_, 'weights': gmm.weights_, 'variances': gmm.covariances_}\n",
    "    return gmm_dict\n",
    "\n",
    "\n",
    "def make_dataframe(x, y, method=None):\n",
    "    x = list(x[:, 0].detach().numpy())\n",
    "    y = list(y[:, 0].detach().numpy())\n",
    "    if method is not None:\n",
    "        method = [method for _ in range(len(x))]\n",
    "        df = pd.DataFrame({'x': x, 'y': y, 'Method': method})\n",
    "    else:\n",
    "        df = pd.DataFrame({'x': x, 'y': y})\n",
    "    return df\n",
    "\n",
    "\n",
    "def unzip_dataloader(training_loader):\n",
    "    all_x = []\n",
    "    all_y = []\n",
    "    for data, label in training_loader:\n",
    "        all_x.append(data)\n",
    "        all_y.append(label)\n",
    "    all_x = torch.cat(all_x)\n",
    "    all_y = torch.cat(all_y)\n",
    "    return all_x, all_y\n",
    "\n",
    "\n",
    "def visualize(model_dict, train_loader, test_loader, Y_LB, Y_UB, K, B):\n",
    "    sns.set_theme(palette='colorblind')\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    # Get model outputs\n",
    "    model_df = []\n",
    "    x_test, _ = unzip_dataloader(test_loader)\n",
    "    for model_name in model_dict:\n",
    "        model = model_dict[model_name]\n",
    "        model.eval()\n",
    "        y = model(x_test)\n",
    "        model_df.append(make_dataframe(x_test, y, model_name))\n",
    "\n",
    "    training_df = make_dataframe(*unzip_dataloader(train_loader), 'Training')\n",
    "    test_df = make_dataframe(*unzip_dataloader(test_loader), 'Testing')\n",
    "    oracle_df = make_dataframe(*unzip_dataloader(test_loader), 'Oracle')\n",
    "\n",
    "    # plot oracle and predictions\n",
    "    sns.lineplot(data=pd.concat([oracle_df, *model_df], ignore_index=True), x='x', y='y', hue='Method', ax=ax1)\n",
    "\n",
    "    # plot data points\n",
    "    sns.scatterplot(data=training_df, x='x', y='y', color='#003ea1', alpha=0.2, linewidths=0, s=100, ax=ax1,\n",
    "                    legend=False)\n",
    "\n",
    "    ax1.set_xlim((Y_LB - B) / K, (Y_UB - B) / K)\n",
    "    ax1.set_ylim(Y_LB, Y_UB)\n",
    "    ax1.set_xlabel(r'$x$', fontsize=10)\n",
    "    ax1.set_ylabel(r'$y$', fontsize=10)\n",
    "\n",
    "    # plot training histogram\n",
    "    bins = np.linspace(Y_LB, Y_UB, 20)\n",
    "    sns.histplot(data=training_df, y='y', kde=False, stat='density', hue='Method', common_norm=False, bins=bins, ax=ax2)\n",
    "\n",
    "    # plot kdeplot\n",
    "    sns.kdeplot(data=pd.concat([training_df, *model_df, test_df], ignore_index=True), y='y', hue='Method',\n",
    "                common_norm=False, ax=ax2)\n",
    "\n",
    "    ax2.set_ylim(Y_LB, Y_UB)\n",
    "    ax2.set_xlabel(r'$p(y)$', fontsize=10)\n",
    "    ax2.set_ylabel(r'$y$', fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def hist_3d(ax, data, title, Y_LB, Y_UB, zmax=0.06):\n",
    "    xx, yy = np.mgrid[Y_LB[0].item():Y_UB[0].item():100j, Y_LB[1].item():Y_UB[1].item():100j]\n",
    "    positions = np.vstack([xx.ravel(), yy.ravel()])\n",
    "    values = data.transpose(0, 1).detach().cpu().numpy()\n",
    "    kernel = st.gaussian_kde(values)\n",
    "    f = np.reshape(kernel(positions).T, xx.shape)\n",
    "    surf = ax.plot_surface(xx, yy, f, rstride=1, cstride=1, cmap='coolwarm', edgecolor='none')\n",
    "    ax.set_xlabel('y1')\n",
    "    ax.set_ylabel('y2')\n",
    "    ax.set_zlabel('p(y)')\n",
    "    ax.set_zlim(0, zmax)\n",
    "    ax.set_title(title)\n",
    "    surf.set_clim(vmin=0, vmax=zmax)\n",
    "    ax.view_init(55, 25)\n",
    "\n",
    "\n",
    "def visualize_md(model_dict, train_loader, test_loader, Y_LB, Y_UB):\n",
    "    num_models = len(list(model_dict.keys()))\n",
    "    fig = plt.figure(figsize=((num_models + 2) * 4, 5))\n",
    "    subplot_idx = 1\n",
    "\n",
    "    # train distribution\n",
    "    ax = fig.add_subplot(1, num_models + 2, subplot_idx, projection='3d')\n",
    "    subplot_idx += 1\n",
    "    hist_3d(ax, unzip_dataloader(train_loader)[1], 'Train', Y_LB, Y_UB, zmax=0.14)\n",
    "\n",
    "    # test distribution\n",
    "    ax = fig.add_subplot(1, num_models + 2, subplot_idx, projection='3d')\n",
    "    subplot_idx += 1\n",
    "    hist_3d(ax, unzip_dataloader(test_loader)[1], 'Test', Y_LB, Y_UB)\n",
    "\n",
    "    for model_name in model_dict:\n",
    "        model = model_dict[model_name]\n",
    "        model.eval()\n",
    "        x_test, _ = unzip_dataloader(test_loader)\n",
    "        pred = model(x_test)\n",
    "        ax = fig.add_subplot(1, num_models + 2, subplot_idx, projection='3d')\n",
    "        subplot_idx += 1\n",
    "        hist_3d(ax, pred, model_name, Y_LB, Y_UB)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a linear regressor\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mlp(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_data():\n",
    "    # Training label samples\n",
    "    y_train = DIST_DICT[TRAIN_DIST].sample((NUM_TRAIN_SAMPLES,))\n",
    "    assert len(y_train) == NUM_TRAIN_SAMPLES\n",
    "\n",
    "    # Assume a gaussian noise has been added to observed y\n",
    "    noise_distribution = torch.distributions.MultivariateNormal(torch.zeros(Y_DIM), covariance_matrix=NOISE_COVARIANCE)\n",
    "    noise = noise_distribution.sample((NUM_TRAIN_SAMPLES,))\n",
    "\n",
    "    # then the oracle y should be\n",
    "    y_train_oracle = y_train - noise\n",
    "\n",
    "    x_train = f_inv(y_train_oracle)\n",
    "\n",
    "    # Evaluate on balanced (uniform) y distribution\n",
    "    y_eval = DIST_DICT['uniform'].sample((NUM_VAL_SAMPLES,))\n",
    "    x_eval = f_inv(y_eval)\n",
    "\n",
    "    # Test set\n",
    "    y_test = DIST_DICT['uniform'].sample((NUM_TEST_SAMPLES,))\n",
    "    x_test = f_inv(y_test)\n",
    "\n",
    "    train_loader = DataLoader(DummyDataset(x_train, y_train), BATCH_SIZE, shuffle=True)\n",
    "    eval_loader = DataLoader(DummyDataset(x_eval, y_eval), BATCH_SIZE)\n",
    "    test_loader = DataLoader(DummyDataset(x_test, y_test), BATCH_SIZE)\n",
    "\n",
    "    return train_loader, eval_loader, test_loader\n",
    "\n",
    "\n",
    "def prepare_model():\n",
    "    model = LinearModel(input_dim=X_DIM, output_dim=Y_DIM)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.2)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n",
    "    return model, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, eval_loader, test_loader, model, optimizer, scheduler, criterion):\n",
    "    best_eval_loss = 1e8\n",
    "    model_best = None\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train_loss = AverageMeter('train loss')\n",
    "        model.train()\n",
    "        for data, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(data)\n",
    "            loss = criterion(pred, target)\n",
    "            train_loss.update(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        if (epoch + 1) % PRINT_FREQ == 0:\n",
    "            print('epoch: ', epoch + 1)\n",
    "            model.eval()\n",
    "            eval_loss = AverageMeter('eval loss')\n",
    "            for data, target in eval_loader:\n",
    "                pred = model(data)\n",
    "                loss = F.mse_loss(pred, target)\n",
    "                eval_loss.update(loss.item())\n",
    "\n",
    "            print(train_loss)\n",
    "            print(eval_loss)\n",
    "            print('-' * 10)\n",
    "            if best_eval_loss > eval_loss.avg:\n",
    "                model_best = copy.deepcopy(model)\n",
    "                best_eval_loss = eval_loss.avg\n",
    "\n",
    "    print('best eval loss {:.6f}'.format(best_eval_loss))\n",
    "    model_best.eval()\n",
    "    test_loss = AverageMeter('test loss')\n",
    "    for data, target in test_loader:\n",
    "        pred = model(data)\n",
    "        loss = F.mse_loss(pred, target)\n",
    "        test_loss.update(loss.item())\n",
    "    print(test_loss)\n",
    "    print('=' * 20)\n",
    "    return model_best, test_loss.avg\n",
    "\n",
    "\n",
    "def train_model(train_loader, eval_loader, test_loader):\n",
    "    gmm = get_gmm(dist=DIST_DICT[TRAIN_DIST], n_components=1)\n",
    "    criteria = {\n",
    "        'MSE': nn.MSELoss(),\n",
    "        'Reweight': ReweightL2(DIST_DICT[TRAIN_DIST]),\n",
    "        'GAI': GAILossMD(init_noise_sigma=NOISE_SIGMA, gmm=gmm),\n",
    "        'BMC': BMCLossMD(init_noise_sigma=NOISE_SIGMA),\n",
    "        # For learnable noise, we assume we don't know the ground truth noise scale\n",
    "        # Therefore we multiply an offset 1.5 to the ground truth noise scale\n",
    "        'GAI Learnable Noise': GAILossMD(init_noise_sigma=1.5 * NOISE_SIGMA, gmm=gmm),\n",
    "        'BMC Learnable Noise': BMCLossMD(init_noise_sigma=1.5 * NOISE_SIGMA),\n",
    "    }\n",
    "    criteria = {k: criteria[k] for k in CRITERIA_TO_USE}  # Only use selected criteria\n",
    "    perf_stats = {}\n",
    "    models_trained = {}\n",
    "\n",
    "    for criterion_name, criterion in criteria.items():\n",
    "        print(\"Training with distribution {} and criterion {}\".format(TRAIN_DIST, criterion_name))\n",
    "        model, optimizer, scheduler = prepare_model()\n",
    "        if 'Learnable Noise' in criterion_name:\n",
    "            optimizer.add_param_group({'params': criterion.parameters(), 'lr': 0.01})\n",
    "        model_best, perf_stats[criterion_name] = \\\n",
    "            train(train_loader, eval_loader, test_loader, model, optimizer, scheduler, criterion)\n",
    "        models_trained[criterion_name] = model_best\n",
    "\n",
    "    print('Final results')\n",
    "    for method in perf_stats:\n",
    "        print('{0: <20}: {1:.6f}'.format(method, perf_stats[method]))\n",
    "    return models_trained\n",
    "\n",
    "\n",
    "def main():\n",
    "    train_loader, eval_loader, test_loader = prepare_data()\n",
    "    models_trained = train_model(train_loader, eval_loader, test_loader)\n",
    "    visualize_md(models_trained, train_loader, test_loader, Y_LB, Y_UB)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lettuce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ffccc2db1508bf0f1c12d6e67b17722cce250e5750ff7863e7a8be01e188aed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
